{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301afd14",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "Welcome, young deep learning adventurer! Before we embark on our journey to build an Autoencoder for the famous MNIST dataset, we need to gather our tools. In the world of PyTorch, that means importing some essential libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb39900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d4a6c4",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess MNIST Data\n",
    "Now, we need some data to work with. The MNIST dataset consists of handwritten digits (0-9), and it's our mission to compress and reconstruct them using an Autoencoder!\n",
    "Let's load the data and apply some necessary transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03fe7913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 3.85MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 53.6kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 841kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a transformation to convert images to tensors and normalize them\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "print('MNIST dataset loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93937b12",
   "metadata": {},
   "source": [
    "## Step 3: Define the Autoencoder Architecture\n",
    "It's time to design our magical Autoencoder! An Autoencoder is a neural network that learns to encode data into a lower-dimensional space (the bottleneck) and then reconstructs it back to its original form.\n",
    "Our architecture will have an Encoder and a Decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d987cb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder model defined!\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 28*28),\n",
    "            nn.Tanh(),\n",
    "            nn.Unflatten(1, (1, 28, 28))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "print('Autoencoder model defined!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702ee364",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Model, Loss Function, and Optimizer\n",
    "Now that we have our Autoencoder model, let's summon the loss function and optimizer to help train it.\n",
    "The Mean Squared Error (MSE) loss will measure how different the reconstructed images are from the originals, and the Adam optimizer will guide our model toward enlightenment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445fcdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, loss function, and optimizer initialized!\n",
      "device: cpu\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): LeakyReLU(negative_slope=0.2)\n",
      "    (7): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.2)\n",
      "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2)\n",
      "    (9): Linear(in_features=512, out_features=784, bias=True)\n",
      "    (10): Tanh()\n",
      "    (11): Unflatten(dim=1, unflattened_size=(1, 28, 28))\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loss: MSELoss()\n",
      "----------------------------------------------------------------------------------------------------\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "print('Model, loss function, and optimizer initialized!')\n",
    "print(f'device: {device}')\n",
    "print('-' * 100)\n",
    "print(f'model: {model}')\n",
    "print('-' * 100)\n",
    "print(f'Loss: {criterion}')\n",
    "print('-' * 100)\n",
    "print(f'optimizer: {optimizer}')\n",
    "print('-' * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c33dc",
   "metadata": {},
   "source": [
    "## Step 5: Train the Autoencoder\n",
    "Training time! We'll loop through multiple epochs, feeding the Autoencoder images from the MNIST dataset and letting it learn to compress and reconstruct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a16bfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Loss: 0.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Loss: 0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Loss: 0.0480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Loss: 0.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Loss: 0.0389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Loss: 0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Loss: 0.0344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Loss: 0.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Loss: 0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Loss: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Loss: 0.0306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Loss: 0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Loss: 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Loss: 0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Loss: 0.0282\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 25\n",
    "print('Starting training...')\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, _ in tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
    "print('Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536e1dd",
   "metadata": {},
   "source": [
    "## Step 6: Test the Autoencoder and Visualize Results\n",
    "Let's see how well our Autoencoder has learned its magic! We'll pass test images through it and visualize both the original and reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "118d121e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying test images...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_images(original, reconstructed, num_images=5):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(original[i].cpu().squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(2, num_images, i + 1 + num_images)\n",
    "        plt.imshow(reconstructed[i].cpu().squeeze().detach().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Test Images\n",
    "test_images, _ = next(iter(testloader))\n",
    "test_images = test_images.to(device)\n",
    "reconstructed_images = model(test_images)\n",
    "print('Displaying test images...')\n",
    "show_images(test_images, reconstructed_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce945394",
   "metadata": {},
   "source": [
    "## Step 7: Save and Load the Model\n",
    "We've successfully trained our Autoencoder, but we don't want to lose our hard-earned knowledge.\n",
    "Let's save the model and learn how to load it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a418f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'autoencoder.pth')\n",
    "print('Model saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da00eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
